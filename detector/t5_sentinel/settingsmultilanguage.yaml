id: models-large.multilanguage.init_parall.1.17

mode: training

epochs: 15

backbone: 
  name: mt5-large
  modelMaxLen: 1024

dataset:
  - label: Human
    token: <extra_id_0>
    token_id: 250101
    root: data/split/open-web-text
  - label: ChatGPT
    token: <extra_id_1>
    token_id: 250100
    root: data/split/open-gpt-text

dataloader:
  batch_size: 2
  num_workers: 2
  dataset_name: semeval
  taskType: A
  language: multi

tokenizer:
  padding: true
  truncation: true
  return_tensors: pt

optimizer:
  lr: 1.0e-4
  weight_decay: 5.0e-5
  batch_size: 128
